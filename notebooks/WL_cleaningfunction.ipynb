{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f4f737-e548-47fa-8c47-d43b1da7fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import IFrame, display\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296c3ba-ec27-4880-ab15-e339abad93cf",
   "metadata": {},
   "source": [
    "# ðŸ§¹Cleaning cleaning functions\n",
    "\n",
    "The company name cleaning function I've been working with explodes to 30GB in memory. It seriously shouldn't. Worth a refactor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56249c2-d971-4e83-8337-4a321a63a31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/jovyan/company-matching/notebooks, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/home/jovyan/company-matching/notebooks, universal_newlines=False, shell=None, istream=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import locations as loc\n",
    "from src.data import utils as du\n",
    "from src.data.star import Star\n",
    "from src.data.datasets import Dataset\n",
    "from src.data.probabilities import Probabilities\n",
    "from src.data.clusters import Clusters\n",
    "from src.link.splink_linker import SplinkLinker\n",
    "from src.config import link_pipeline, stopwords\n",
    "from src.features.clean_complex import clean_comp_names\n",
    "from src.features.clean_basic import clean_company_name, list_join_to_string\n",
    "\n",
    "import splink.duckdb.comparison_library as cl\n",
    "import splink.duckdb.comparison_template_library as ctl\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import duckdb\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f48ba-909b-49ac-86d8-c737308192f8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Grab some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d0cbb8-2dce-473c-ac90-2a6911e55f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "star = Star(\n",
    "    schema = os.getenv(\"SCHEMA\"),\n",
    "    table = os.getenv(\"STAR_TABLE\")\n",
    ")\n",
    "probabilities = Probabilities(\n",
    "    schema = os.getenv(\"SCHEMA\"),\n",
    "    table = os.getenv(\"PROBABILITIES_TABLE\"),\n",
    "    star = star\n",
    ")\n",
    "clusters = Clusters(\n",
    "    schema = os.getenv(\"SCHEMA\"),\n",
    "    table = os.getenv(\"CLUSTERS_TABLE\"),\n",
    "    star = star\n",
    ")\n",
    "cl_x_exp=SplinkLinker.load(\n",
    "    path=Path(loc.DATA_SUBDIR['raw'], 'ch_x_exp.pickle')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70080f-3545-49d3-934b-56ce675e3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_x_exp = SplinkLinker(\n",
    "    dataset = Dataset(\n",
    "        star_id=54717,\n",
    "        star=star\n",
    "    ), \n",
    "    probabilities=probabilities, \n",
    "    clusters=clusters, \n",
    "    n=2\n",
    ")\n",
    "cl_x_exp.get_data(\n",
    "    cluster_select={\n",
    "        '\"companieshouse\".\"companies\"': [\n",
    "            \"company_name as company_name\",\n",
    "            \"postcode as postcode\"\n",
    "        ]\n",
    "    },\n",
    "    dim_select=[\n",
    "        \"id\",\n",
    "        \"company_name\",\n",
    "        \"postcode\"\n",
    "    ]\n",
    ")\n",
    "cl_x_exp.save(path=Path(loc.DATA_SUBDIR['raw'], 'ch_x_exp.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db892e-453a-4b5a-a22e-2bc24f83512e",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de440e6-fc0e-4445-94b4-5cf06612e186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = cl_x_exp.dim_raw.sample(int(1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4c3e6-d3ce-4dd9-a310-6a04e6a8c40d",
   "metadata": {},
   "source": [
    "What does this function actually do?\n",
    "\n",
    "* Standard clean of company name, returns tokens in an array\n",
    "* Standard clean of an array of company's second names -- this as array of arrays, presumably\n",
    "* Removes stopwords from the cleaned names\n",
    "    * By joining in the stopwords to EVERY ROW\n",
    "* Adds lists of terms removed etc (with pandas functions)\n",
    "\n",
    "I think we can make it way more efficient by overwriting columns, keeping it in duckdb, and ditching columns that aren't needed in prod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bbdc32-4615-462e-929d-2685b28488c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df = duckdb.sql(\"\"\"\n",
    "    select\n",
    "        *,\n",
    "        [company_name, company_name] as secondary_names\n",
    "    from\n",
    "        df;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd3d84a-8baf-4df3-87b4-ed79524cf5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_except(input_col_name, terms_to_remove):\n",
    "    return rf\"\"\"\n",
    "    array_filter(\n",
    "        {input_col_name},\n",
    "        x -> not array_contains({terms_to_remove}, x)\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb37824-389b-4a7a-afb7-3ab99a83e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comp_names(\n",
    "    df, primary_col: str, secondary_col: str = None, stopwords: str = stopwords\n",
    "):\n",
    "    clean_primary_sql = f\"\"\"\n",
    "        select\n",
    "            *\n",
    "            replace ({clean_company_name(primary_col)} as {primary_col})\n",
    "        from\n",
    "            df;\n",
    "    \"\"\"\n",
    "    stopwords_primary_sql = f\"\"\"\n",
    "        select\n",
    "            *\n",
    "            replace (\n",
    "                {list_join_to_string(\n",
    "                    array_except(primary_col, stopwords)\n",
    "                )}\n",
    "                as {primary_col}\n",
    "            )\n",
    "        from\n",
    "            df;\n",
    "    \"\"\"\n",
    "    \n",
    "    if secondary_col is not None:\n",
    "        unnest_sql = f\"\"\"\n",
    "            select\n",
    "                *\n",
    "                replace (unnest({secondary_col}) as {secondary_col})\n",
    "            from\n",
    "                df;\n",
    "        \"\"\"\n",
    "        clean_secondary_sql = f\"\"\"\n",
    "            select\n",
    "                *\n",
    "                replace ({clean_company_name(secondary_col)} as {secondary_col})\n",
    "            from\n",
    "                df;\n",
    "        \"\"\"\n",
    "        stopwords_secondary_sql = f\"\"\"\n",
    "            select\n",
    "                *\n",
    "                replace (\n",
    "                    {list_join_to_string(\n",
    "                        array_except(secondary_col, stopwords)\n",
    "                    )}\n",
    "                    as {secondary_col}\n",
    "                )\n",
    "            from\n",
    "                df;\n",
    "        \"\"\"\n",
    "        renest_sql = f\"\"\"\n",
    "            select\n",
    "                *\n",
    "                replace (list({secondary_col}) as {secondary_col})\n",
    "            from\n",
    "                df\n",
    "            group by all;\n",
    "        \"\"\"\n",
    "        to_run = [\n",
    "            unnest_sql, \n",
    "            clean_secondary_sql, \n",
    "            stopwords_secondary_sql, \n",
    "            renest_sql,\n",
    "            clean_primary_sql,\n",
    "            stopwords_primary_sql\n",
    "        ]\n",
    "    else:\n",
    "        to_run = [\n",
    "            clean_primary_sql,\n",
    "            stopwords_primary_sql\n",
    "        ]\n",
    "\n",
    "    for sql in to_run:\n",
    "        df = duckdb.sql(sql)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d7c8a-0046-4193-b4ff-ab7339e4f7d3",
   "metadata": {},
   "source": [
    "TODO: this gives kernel death with no reason why. Look into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ec261-a445-4206-afa7-7cfa743eda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_comp_names(\n",
    "    df,\n",
    "    primary_col=\"company_name\",\n",
    "    secondary_col=None,\n",
    "    stopwords=stopwords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9913465a-8584-45b4-bec6-8cb6b7987a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177873</th>\n",
       "      <td>2657918</td>\n",
       "      <td>PORTOBELLO FASHION LTD</td>\n",
       "      <td>NW10 7LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126049</th>\n",
       "      <td>677887</td>\n",
       "      <td>KINGSWOOD FRAMES AND MIRRORS/FRAMEWORK STUDIO LTD</td>\n",
       "      <td>SY21 8JF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58474</th>\n",
       "      <td>3155979</td>\n",
       "      <td>DAVID JOHN WRIGHT</td>\n",
       "      <td>SA18 3LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21351</th>\n",
       "      <td>1049549</td>\n",
       "      <td>A V ENGINEERING SERVICES LTD</td>\n",
       "      <td>SG8 6DN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193354</th>\n",
       "      <td>2233514</td>\n",
       "      <td>ROHM (GREAT BRITAIN) LIMITED</td>\n",
       "      <td>KT2 6HH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146534</th>\n",
       "      <td>2017015</td>\n",
       "      <td>METALLIMONSTERS LTD</td>\n",
       "      <td>HU16 5DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250358</th>\n",
       "      <td>1248660</td>\n",
       "      <td>WILLIAM GIBBONS AND SONS LIMITED</td>\n",
       "      <td>WV13 3XT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138536</th>\n",
       "      <td>3339364</td>\n",
       "      <td>MAF S.R.L. UNIPERSONALE</td>\n",
       "      <td>AB10 1ZP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204664</th>\n",
       "      <td>2621858</td>\n",
       "      <td>SIDDEQ AHMED MOHAMMED</td>\n",
       "      <td>LE1 2LT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219642</th>\n",
       "      <td>218040</td>\n",
       "      <td>SYSTOR SYSTEMS UK LTD</td>\n",
       "      <td>KT3 3TL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                       company_name  postcode\n",
       "177873  2657918                             PORTOBELLO FASHION LTD  NW10 7LF\n",
       "126049   677887  KINGSWOOD FRAMES AND MIRRORS/FRAMEWORK STUDIO LTD  SY21 8JF\n",
       "58474   3155979                                  DAVID JOHN WRIGHT  SA18 3LF\n",
       "21351   1049549                       A V ENGINEERING SERVICES LTD   SG8 6DN\n",
       "193354  2233514                       ROHM (GREAT BRITAIN) LIMITED   KT2 6HH\n",
       "...         ...                                                ...       ...\n",
       "146534  2017015                                METALLIMONSTERS LTD  HU16 5DL\n",
       "250358  1248660                   WILLIAM GIBBONS AND SONS LIMITED  WV13 3XT\n",
       "138536  3339364                            MAF S.R.L. UNIPERSONALE  AB10 1ZP\n",
       "204664  2621858                              SIDDEQ AHMED MOHAMMED   LE1 2LT\n",
       "219642   218040                              SYSTOR SYSTEMS UK LTD   KT3 3TL\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3875b5-2c49-4452-b7fe-2ba048bd8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_col = \"company_name\"\n",
    "clean_primary_sql = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace ({clean_company_name(primary_col)} as {primary_col})\n",
    "    from\n",
    "        df;\n",
    "\"\"\"\n",
    "stopwords_primary_sql = f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace (\n",
    "            {list_join_to_string(\n",
    "                array_except(primary_col, stopwords)\n",
    "            )}\n",
    "            as {primary_col}\n",
    "        )\n",
    "    from\n",
    "        df;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f740ec-4ded-4cc4-935d-86344707d1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚   id    â”‚                         company_name                          â”‚ postcode â”‚\n",
       "â”‚  int64  â”‚                           varchar[]                           â”‚ varchar  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 2657918 â”‚ [portobello, fashion, limited]                                â”‚ NW10 7LF â”‚\n",
       "â”‚  677887 â”‚ [kingswood, frames, and, mirrors, framework, studio, limited] â”‚ SY21 8JF â”‚\n",
       "â”‚ 3155979 â”‚ [david, john, wright]                                         â”‚ SA18 3LF â”‚\n",
       "â”‚ 1049549 â”‚ [a, v, engineering, services, limited]                        â”‚ SG8 6DN  â”‚\n",
       "â”‚ 2233514 â”‚ [rohm, great, britain, limited]                               â”‚ KT2 6HH  â”‚\n",
       "â”‚ 2564275 â”‚ [alan, jamieson, site, services, limited]                     â”‚ BR6 6HR  â”‚\n",
       "â”‚ 1135889 â”‚ [studio, wayne, mcgregor, limited]                            â”‚ E15 2GW  â”‚\n",
       "â”‚ 1919098 â”‚ [p, k, veneering, limited]                                    â”‚ CW1 6FA  â”‚\n",
       "â”‚   35858 â”‚ [the, london, mint, office, limited]                          â”‚ W6 7BA   â”‚\n",
       "â”‚ 2504969 â”‚ [books, illustrated, limited]                                 â”‚ SP2 8BL  â”‚\n",
       "â”‚    Â·    â”‚        Â·                                                      â”‚    Â·     â”‚\n",
       "â”‚    Â·    â”‚        Â·                                                      â”‚    Â·     â”‚\n",
       "â”‚    Â·    â”‚        Â·                                                      â”‚    Â·     â”‚\n",
       "â”‚ 2458866 â”‚ [kevin, munday]                                               â”‚ RG21 3FB â”‚\n",
       "â”‚   37037 â”‚ [platts, harris, agricultural, group, limited]                â”‚ NG22 0LH â”‚\n",
       "â”‚ 1599138 â”‚ [istidama, limited]                                           â”‚ CH66 1ST â”‚\n",
       "â”‚ 1881471 â”‚ [hawkeye, limited]                                            â”‚ B70 0BN  â”‚\n",
       "â”‚ 3328304 â”‚ [pax, technology, europe, limite, d]                          â”‚ GU21 2AY â”‚\n",
       "â”‚ 2017015 â”‚ [metallimonsters, limited]                                    â”‚ HU16 5DL â”‚\n",
       "â”‚ 1248660 â”‚ [william, gibbons, and, sons, limited]                        â”‚ WV13 3XT â”‚\n",
       "â”‚ 3339364 â”‚ [maf, srl, unipersonale]                                      â”‚ AB10 1ZP â”‚\n",
       "â”‚ 2621858 â”‚ [siddeq, ahmed, mohammed]                                     â”‚ LE1 2LT  â”‚\n",
       "â”‚  218040 â”‚ [systor, systems, uk, limited]                                â”‚ KT3 3TL  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ? rows (>9999 rows, 20 shown)                                            3 columns â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(clean_primary_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81840c98-8ce4-44c9-9487-ec3b33501a84",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error:  Invalid LIST argument to array_filter!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mduckdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopwords_primary_sql\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error:  Invalid LIST argument to array_filter!"
     ]
    }
   ],
   "source": [
    "duckdb.sql(stopwords_primary_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a58ea0ec-1221-4a49-a8eb-3277906334db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df2 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace (unnest(secondary_names) as secondary_names)\n",
    "    from\n",
    "        sec_df;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ae7b6b6-e45b-4960-96d3-62cfa6dc2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df3 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace ({clean_company_name(\"secondary_names\")} as secondary_names)\n",
    "    from\n",
    "        sec_df2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eec4d939-95ea-4ff8-a168-3a2ea5c1200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df4 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace (\n",
    "            {\n",
    "                list_join_to_string(\n",
    "                    array_except(\"secondary_names\", stopwords)\n",
    "                )\n",
    "            }\n",
    "            as secondary_names\n",
    "        )\n",
    "    from\n",
    "        sec_df3;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6891b461-4e94-4e3f-8341-89d89947b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_df5 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace (list(secondary_names) as secondary_names)\n",
    "    from\n",
    "        sec_df4\n",
    "    group by all;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed4f1b9-08ab-4a89-9822-248578013efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_except(input_col_name, terms_to_remove):\n",
    "    return rf\"\"\"\n",
    "    array_filter(\n",
    "        {input_col_name},\n",
    "        x -> not array_contains({terms_to_remove}, x)\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c7e93e-b0e4-414e-b502-0a92eea2a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace ({clean_company_name(\"company_name\")} as company_name)\n",
    "    from\n",
    "        df;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe14155-f93c-460e-ae18-833ae7f2c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = duckdb.sql(f\"\"\"\n",
    "    select\n",
    "        *\n",
    "        replace (\n",
    "            {\n",
    "                list_join_to_string(\n",
    "                    array_except(\"company_name\", stopwords)\n",
    "                )\n",
    "            }\n",
    "            as company_name\n",
    "        )\n",
    "    from\n",
    "        df2;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dba1858-6155-4612-b53a-2629f5fb1eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚   id    â”‚                 company_name                 â”‚ postcode â”‚\n",
       "â”‚  int64  â”‚                   varchar                    â”‚ varchar  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ 2720694 â”‚ lloyd julian                                 â”‚ NR6 7GA  â”‚\n",
       "â”‚  647217 â”‚ niels larsen                                 â”‚ WF5 0HP  â”‚\n",
       "â”‚  505204 â”‚ churchill fire                               â”‚ EC2A 3QR â”‚\n",
       "â”‚  618395 â”‚ buzz pinky                                   â”‚ PO9 2NA  â”‚\n",
       "â”‚ 3361781 â”‚ t f tull                                     â”‚ WD18 8RH â”‚\n",
       "â”‚  650314 â”‚ vct                                          â”‚ GU24 8HU â”‚\n",
       "â”‚ 2310276 â”‚ showerdrape std                              â”‚ M17 1DB  â”‚\n",
       "â”‚  249534 â”‚ maquet                                       â”‚ NE35 9PZ â”‚\n",
       "â”‚ 2321202 â”‚ fiera capital iom                            â”‚ IM1 1EU  â”‚\n",
       "â”‚ 2893212 â”‚ nature s buddy                               â”‚ SW17 0QF â”‚\n",
       "â”‚    Â·    â”‚       Â·                                      â”‚    Â·     â”‚\n",
       "â”‚    Â·    â”‚       Â·                                      â”‚    Â·     â”‚\n",
       "â”‚    Â·    â”‚       Â·                                      â”‚    Â·     â”‚\n",
       "â”‚ 1957717 â”‚ base childrenswear                           â”‚ IG8 8HF  â”‚\n",
       "â”‚   50716 â”‚ rascal clothing                              â”‚ EN11 0BE â”‚\n",
       "â”‚ 2145000 â”‚ gw wines                                     â”‚ WA14 4QF â”‚\n",
       "â”‚ 1754977 â”‚ jyw                                          â”‚ TA2 7AS  â”‚\n",
       "â”‚  891327 â”‚ digital print                                â”‚ NN7 2EG  â”‚\n",
       "â”‚ 1624804 â”‚ lff scotland                                 â”‚ AB32 6JL â”‚\n",
       "â”‚ 2628894 â”‚ dandara iom holdings                         â”‚ IM2 2SA  â”‚\n",
       "â”‚ 1415928 â”‚ ecom                                         â”‚ BD10 9TQ â”‚\n",
       "â”‚ 1701108 â”‚ shen zhen shi lang ma ke ji you xian gong si â”‚ AB10 1ZP â”‚\n",
       "â”‚ 1109511 â”‚ millerbrown                                  â”‚ HD9 6EB  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ ? rows (>9999 rows, 20 shown)                           3 columns â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d9479-aac2-45ec-b710-dd5be1f0b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_clean_company_name = f\"\"\"\n",
    "    select\n",
    "        {clean_company_name(primary_col)} as company_name_arr,\n",
    "        {\n",
    "            f\"{clean_company_name(secondary_col)} as secondary_names_arr, \"\n",
    "            if secondary_col\n",
    "            else \"\"\n",
    "        }\n",
    "        *\n",
    "    from df\n",
    "\"\"\"\n",
    "names_cleaned = duckdb.sql(sql_clean_company_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4157cf-ab24-4d6e-85e9-3c7de3eb4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"function\": clean_comp_names,\n",
    "\"arguments\": {\n",
    "    \"primary_col\": \"company_name\",\n",
    "    \"secondary_col\": None,\n",
    "    \"stopwords\": stopwords,\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80dbd5-f446-4ce3-8196-f012652edf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"function\": clean_comp_names,\n",
    "\"arguments\": {\n",
    "    \"primary_col\": \"company_name\",\n",
    "    \"secondary_col\": None,\n",
    "    \"stopwords\": stopwords,\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4affc-4f6c-4660-81fd-540aacd15055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comp_names(\n",
    "    df, primary_col: str, secondary_col: str = None, stopwords: str = stopwords\n",
    "):\n",
    "    \"\"\"\n",
    "    Lower case, remove punctuation & tokenise the primary company name into an array.\n",
    "    Extract tokens into: 'unusual' and 'stopwords'. Dedupe. Sort alphabetically.\n",
    "    Untokenise the unusual words back to a string.\n",
    "\n",
    "    Args:\n",
    "        df: a dataframe\n",
    "        primary_col: a column containing the company's main name\n",
    "        secondary_col: a column containing an array of the company's\n",
    "            secondary names\n",
    "        stopwords: a list of stopwords to use for this clean\n",
    "    Returns:\n",
    "        dataframe: company number, 'unusual' tokens', most common 3 tokens,\n",
    "            most common 4 to 6 tokens, list of previous names of company, postcode.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Refactor the silly nested f-strings\n",
    "\n",
    "    # CLEAN and TOKENISE\n",
    "    # To a new dataframe\n",
    "    sql_clean_company_name = f\"\"\"\n",
    "    select\n",
    "        {clean_company_name(primary_col)} as company_name_arr,\n",
    "        {\n",
    "            f\"{clean_company_name(secondary_col)} as secondary_names_arr, \"\n",
    "            if secondary_col\n",
    "            else \"\"\n",
    "        }\n",
    "        *\n",
    "    from df\n",
    "    \"\"\"\n",
    "    names_cleaned = duckdb.sql(sql_clean_company_name)  # noqa:F841\n",
    "\n",
    "    # Define STOPWORDS\n",
    "    # And join them in\n",
    "    stopword_tokens = pd.DataFrame({\"token_array\": [stopwords]})  # noqa:F841\n",
    "    sql_companies_arr_with_top = \"\"\"\n",
    "    select\n",
    "        *,\n",
    "        (select * from stopword_tokens) as stopwords\n",
    "    from names_cleaned\n",
    "    \"\"\"\n",
    "    with_common_terms = duckdb.sql(sql_companies_arr_with_top)  # noqa:F841\n",
    "\n",
    "    # EXTRACT the UNUSUAL and STOPWORD tokens\n",
    "    # We want the weird stuff from company names\n",
    "    # TODO: leave name_unusual_tokens (and secondary...) as array & remove split() below\n",
    "    def secondary_name_unusual_tokens():\n",
    "        # DuckDB needs a refactor, sorry\n",
    "        return list_join_to_string(array_except(\"secondary_names_arr\", \"stopwords\"))\n",
    "\n",
    "    def cat_names_tokens_stopwords(primary_arr, secondary_arr, stopwords):\n",
    "        # DuckDB needs a refactor, sorry\n",
    "        # return array_intersect(\"secondary_names_arr\", \"stopwords\")\n",
    "        primary = rf\"{array_intersect(primary_arr, stopwords)}\"\n",
    "        secondary = rf\"{array_intersect(primary_arr, stopwords)}\"\n",
    "\n",
    "        if secondary_arr:\n",
    "            return rf\"\"\"\n",
    "                array_cat(\n",
    "                    {primary},\n",
    "                    {secondary}\n",
    "                )\n",
    "            \"\"\"\n",
    "        else:\n",
    "            return rf\"{primary}\"\n",
    "\n",
    "    sql_manipulate_arrays = f\"\"\"\n",
    "    select\n",
    "        *,\n",
    "        {\n",
    "            list_join_to_string(\n",
    "                array_except(\"company_name_arr\", \"stopwords\")\n",
    "            )\n",
    "        }\n",
    "            as name_unusual_tokens,\n",
    "        {\n",
    "            (\n",
    "                f\"{secondary_name_unusual_tokens()} \"\n",
    "                \"as secondary_name_unusual_tokens\"\n",
    "            )\n",
    "            if secondary_col\n",
    "            else \"\"\n",
    "        }\n",
    "        {\n",
    "            cat_names_tokens_stopwords(\n",
    "                \"company_name_arr\",\n",
    "                \"secondary_names_arr\",\n",
    "                stopwords\n",
    "            )\n",
    "        } as names_tokens_stopwords\n",
    "    from with_common_terms\n",
    "    \"\"\"\n",
    "    clean = duckdb.sql(sql_manipulate_arrays)\n",
    "\n",
    "    clean_df = clean.df()\n",
    "\n",
    "    # DEDUPE names_tokens_stopwords\n",
    "    clean_df[\"name_unusual_tokens\"] = clean_df.name_unusual_tokens.apply(\n",
    "        lambda x: \" \".join(sorted(set(x.split()))) if pd.notnull(x) else x\n",
    "    )\n",
    "    if secondary_col:\n",
    "        clean_df[\n",
    "            \"secondary_name_unusual_tokens\"\n",
    "        ] = clean_df.secondary_name_unusual_tokens.apply(\n",
    "            lambda x: \" \".join(sorted(set(x.split()))) if pd.notnull(x) else x\n",
    "        )\n",
    "\n",
    "    clean_df[\"names_tokens_stopwords\"] = clean_df.names_tokens_stopwords.apply(\n",
    "        lambda x: \" \".join(set(x))\n",
    "    )\n",
    "\n",
    "    # Get HEAD and TAIL characters\n",
    "    # For blocking rules\n",
    "    clean_df[\"name_unusual_tokens_first5\"] = clean_df.name_unusual_tokens.str[:5]\n",
    "    clean_df[\"name_unusual_tokens_last5\"] = clean_df.name_unusual_tokens.str[-5:]\n",
    "\n",
    "    return clean_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_matching",
   "language": "python",
   "name": "company_matching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
